<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <link href="https://fonts.googleapis.com/css?family=M+PLUS+Rounded+1c" rel="stylesheet" type="text/css">
    <title>SpeechDog</title>
   
</head>
<body>
    <p id="title">ぽん・で・すぴーく</p>
    <div class="dog">  
        <img class="base" src="./dog_base.png">
        <canvas id="mouth" width="200" height="200"></canvas>
        <img class="face" src="./dog_face.png">
        <canvas id="mabuta" width="200" height="60"></canvas>
        <p id="msg">......................</p>
        <!-- <img class="mofu" src="./mofu.png"> -->
    </div>
</body>

<script>    
//音声認識APIの使用
const speech = new webkitSpeechRecognition();
//言語を日本語に設定
speech.lang = "ja";
// 音声認識をスタート
window.onclick = function() {
    speech.start();
};

// イベント
speech.addEventListener('result', speech2text);
    
// 関数
function speech2text(event) {
    let text = event.results[0][0].transcript;
    
    // 音声認識で取得した情報を、コンソール画面に表示
    console.log(text);
    
    // 認識された「言葉(text)」を、表示用のdivタグに代入する
    // const msg = document.getElementById("msg");

    // オウム返し
    const synthes = new SpeechSynthesisUtterance(text);
    synthes.rate = 1.2 // 速度 0.1-10 初期値:1 (倍速なら2, 半分の倍速なら0.5)
    synthes.pitch = 1.2 // 高さ 0-2 初期値:1
    synthes.volume = 0.75 // 音量 0-1 初期値:1

    speechSynthesis.speak(synthes);
    synthes.onend = () => {
        setTimeout(() => {
            nico(); // 読み終えてからの処理
            speech.start();
        }, 500);
    }

    // 一文字ずつ表示
    var count = 0;
    var printString;

    function disp() {
        msg.innerText = text.substring(0, count++);
        if(count <= text.length) {
            setTimeout(disp, 90);
            // setTimeout(disp, 90, text); OK
            // setTimeout(disp(), 90); NG
        }
    }
    disp();
    talk();
}
    
// まばたき
window.addEventListener("load", eventWindowLoaded);
function eventWindowLoaded () { 
    draw();
}
const draw = () => {
    const canvas = document.getElementById("mabuta"); 
    if(canvas.getContext) {
        const ctx = canvas.getContext("2d"); 
        
        let count2 = 0;
        matataki = setInterval( () => {
            let step = 0;
            let flag = true;
            let count = 0;
            // setInterval(イベント, 処理間隔)でイベントを処理間隔ごとに繰り返す
            mabataki = setInterval(() => {
                // 描画スタイルの初期状態を保存する 　
                ctx.save();
                // 初期化
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                if(flag){
                    ctx.translate(30, step++);
                    if(step>30) {
                        flag = false;
                    }
                } else {
                    ctx.translate(30, step--);
                    if(step === 0) {
                        flag = true;
                    }
                }
                ctx.fillStyle="#ffc400e1" // 塗りつぶし色
                // ctx.fillStyle="#000000"
                ctx.fillRect(0, 0, 40, 30) // 正方形を描画
                ctx.fillRect(100, 0, 40, 30)
                ctx.restore(); // 描画スタイルを復元（初期状態に戻す）
                
                count++;
                if(count > 60*2){
                    clearInterval(mabataki);　//idをclearIntervalで指定している
                }
            }, 8);

            count2++
            if(count2 > 2){ 
                clearInterval(matataki);　//idをclearIntervalで指定している
            }
        }, 2700);
    } 
}

// にっこり
const nico = () => {
    const canvas = document.getElementById("mabuta"); 
    if(canvas.getContext) {
        const ctx = canvas.getContext("2d");
        ctx.save();
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.fillStyle="#ffc400"
        ctx.beginPath();
        ctx.ellipse(54, 54, 16, 10, 0, 0, 2*Math.PI);
        ctx.ellipse(148, 54, 16, 10, 0, 0, 2*Math.PI);
        ctx.fill();
        setTimeout(() => {
            draw(); // 読み終えてからの処理
        }, 1800);
        // ctx.restore(); // 描画スタイルを復元（初期状態に戻す）
        // cstx.clearRect(0, 0, canvas.width, canvas.height);
    }
}

// 口が動く
const talk = () => {
    const canvas = document.getElementById('mouth');
    if(canvas.getContext) {
        const ctx = canvas.getContext("2d"); 

        let flag = true;
        let mouse_width = 16;
        let mouse_height = 12;
        let count = 0;
        let step = 0;
        // setInterval(イベント, 処理間隔)でイベントを処理間隔ごとに繰り返す
        speak = setInterval(() => {
            // 描画スタイルの初期状態を保存する 　
            ctx.save();
            // 初期化
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.fillStyle="#9e3122";

            // // 楕円を描画
            // if(flag){
            //     ctx.beginPath();
            //     ctx.ellipse(100, 100, mouse_width--, mouse_height++, 0, 0, 2*Math.PI);
            //     ctx.fill();
            //     if(mouse_height > 14) {
            //         flag = false;
            //     } 
            // } else {
            //     ctx.beginPath();
            //     ctx.ellipse(100, 100, mouse_width++, mouse_height--, 0, 0, 2*Math.PI);
            //     ctx.fill();
            //     if(mouse_width > 20) {
            //         flag = true;
            //     } 
            // }

            if(flag){
                ctx.translate(0, step++);
                if(step>22) {
                    flag = false;
                }
            } else {
                ctx.translate(0, step--);
                if(step === 0) {
                    flag = true;
                }
            }
            ctx.fillStyle="#9e3122";
            ctx.beginPath();
            ctx.ellipse(100, 100, mouse_width, mouse_height, 0, 0, 2*Math.PI);
            ctx.fill();
            ctx.restore();
            
            count++;
            if(count > 40*4 && step === 0){
                clearInterval(speak);　//idをclearIntervalで指定している
                ctx.clearRect(0, 0, canvas.width, canvas.height);
            }    
        }, 7);
    } 
}

    // (文字が消えていく)
    // 発話中は口が動く
    // 音声認識開始で目が大きく、認識中はあいずち
    // ホットワードで認識開始
    // 声を可愛く
</script>

<style type="text/css">
* {
    background-color: #ecc9ac;    
}

body {
    display: flex;
    justify-content: center;
    align-items: center;     
    height: 90vh;
}

.dog {   
    display: flex;
    justify-content: center;
    align-items: center;              
    position: relative;
    /* background-color: rgba(0, 255, 255, 0.144);                            */
}

.base {
    width: 55mm;
    /* background-color: rgba(255, 228, 196, 0.445); */
}

.dog #msg {
    position: absolute;
    top: 62%;
    width: 130px;
    background-color: rgba(34, 22, 0, 0.11);
    border-radius: 8px;
    color: rgba(85, 37, 35, 0.76); 
    font-family: "M PLUS Rounded 1c";
    font-size: 23px;
    font-weight: bold;
    padding: 0px 10px 0px 10px;
}

#mabuta {
    position: absolute;
    background-color: #ff000000;
    top: 22%;
}

.face {
    position: absolute;
    top: 31%;  
    background-color: rgba(0, 0, 0, 0);
    width: 31mm; 
    height: auto;
}

#mouth {
    position: absolute;
    background-color: #9e302200;
    top: 16%;
}

.mofu {
    position: absolute;
    background-color: rgba(0, 0, 0, 0);
    top: -6%;
    left: -24%;
    width: 325px;
}

#title {
    position:absolute;
    top: 0%;
    padding-bottom: 100px;
    font-family: "M PLUS Rounded 1c";
    color: rgb(0, 0, 0);
    font-size: 34px;
    font-weight: bold;
    padding: 0px 10px 0px 10px;
}
</style>

</html>